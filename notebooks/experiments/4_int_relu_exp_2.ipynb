{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285b550c-fe85-469a-9322-979f49e6f9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and processing real IMDB dataset...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-20 14:21:52.393111: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3\n",
      "2026-02-20 14:21:52.393137: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2026-02-20 14:21:52.393144: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.92 GB\n",
      "2026-02-20 14:21:52.393157: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2026-02-20 14:21:52.393164: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Standard Transformer (Continuous FP32) ---\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-20 14:21:53.694931: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 75ms/step - accuracy: 0.7227 - loss: 0.5358 - val_accuracy: 0.8010 - val_loss: 0.4133\n",
      "Epoch 2/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 0.8861 - loss: 0.2781 - val_accuracy: 0.8180 - val_loss: 0.4357\n",
      "Epoch 3/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - accuracy: 0.9257 - loss: 0.1885 - val_accuracy: 0.7595 - val_loss: 0.7048\n",
      "Epoch 4/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - accuracy: 0.9427 - loss: 0.1446 - val_accuracy: 0.8050 - val_loss: 0.5227\n",
      "Epoch 5/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 0.9479 - loss: 0.1311 - val_accuracy: 0.7975 - val_loss: 0.7285\n",
      "Epoch 6/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 69ms/step - accuracy: 0.9690 - loss: 0.0817 - val_accuracy: 0.7875 - val_loss: 0.9921\n",
      "Epoch 7/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 69ms/step - accuracy: 0.9870 - loss: 0.0363 - val_accuracy: 0.7760 - val_loss: 1.2718\n",
      "Epoch 8/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 0.9730 - loss: 0.0640 - val_accuracy: 0.7890 - val_loss: 0.9978\n",
      "Epoch 9/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 0.9711 - loss: 0.0760 - val_accuracy: 0.8015 - val_loss: 0.8582\n",
      "Epoch 10/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 0.9915 - loss: 0.0238 - val_accuracy: 0.7925 - val_loss: 1.1306\n",
      "\n",
      "--- Training Quantized Transformer (Dynamic W4A4) ---\n",
      "Epoch 1/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.7182 - loss: 0.5466 - val_accuracy: 0.7965 - val_loss: 0.4221\n",
      "Epoch 2/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.8816 - loss: 0.2846 - val_accuracy: 0.8275 - val_loss: 0.4058\n",
      "Epoch 3/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.9323 - loss: 0.1794 - val_accuracy: 0.8055 - val_loss: 0.5708\n",
      "Epoch 4/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.9520 - loss: 0.1261 - val_accuracy: 0.7995 - val_loss: 0.6240\n",
      "Epoch 5/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.9505 - loss: 0.1251 - val_accuracy: 0.7915 - val_loss: 0.7249\n",
      "Epoch 6/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 0.9591 - loss: 0.1029 - val_accuracy: 0.8140 - val_loss: 0.6873\n",
      "Epoch 7/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.9842 - loss: 0.0406 - val_accuracy: 0.7530 - val_loss: 1.4099\n",
      "Epoch 8/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.9781 - loss: 0.0562 - val_accuracy: 0.7965 - val_loss: 0.9376\n",
      "Epoch 9/10\n",
      "\u001b[1m16/79\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.9730 - loss: 0.0689"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# ==========================================\n",
    "# 1. Prepare Real Text Data (IMDB Dataset)\n",
    "# ==========================================\n",
    "vocab_size = 10000  # We will use the top 10,000 most frequent words\n",
    "maxlen = 100        # We will truncate/pad reviews to 100 words\n",
    "\n",
    "print(\"Downloading and processing real IMDB dataset...\")\n",
    "# Load the dataset (Keras handles downloading it automatically)\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=vocab_size)\n",
    "\n",
    "# Preprocess: Ensure all sequences are exactly 100 tokens long\n",
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "# We use 10,000 samples for training and 2,000 for validation to keep execution fast\n",
    "x_train, y_train = x_train[:10000], y_train[:10000]\n",
    "x_test, y_test = x_test[:2000], y_test[:2000]\n",
    "\n",
    "# Batch the data for optimization\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(128)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(128)\n",
    "\n",
    "# ==========================================\n",
    "# 2. Define Dynamic W4A4 Quantization (Weights & Activations)\n",
    "# ==========================================\n",
    "@tf.custom_gradient\n",
    "def dynamic_quant_ste(x):\n",
    "    \"\"\"\n",
    "    FORWARD PASS: Dynamic Quantization (Token-wise)\n",
    "    Calculates a unique scale dynamically, preventing massive LLM \n",
    "    outliers from being clamped and destroyed.\n",
    "    \"\"\"\n",
    "    # Find the massive outlier spike (max absolute value) per token vector\n",
    "    abs_max = tf.reduce_max(tf.abs(x), axis=-1, keepdims=True)\n",
    "    \n",
    "    # Stretch our 16 steps (signed 4-bit range [-8, 7]) around the outlier\n",
    "    scale = tf.maximum(abs_max / 7.0, 1e-7)\n",
    "    \n",
    "    # Quantize to integer levels and clamp\n",
    "    x_quant = tf.clip_by_value(tf.round(x / scale), -8.0, 7.0)\n",
    "    \n",
    "    # Dequantize back to scaled \"staircase\" levels (Fake Quantization)\n",
    "    result = x_quant * scale\n",
    "\n",
    "    # BACKWARD PASS: Straight-Through Estimator (STE)\n",
    "    def grad(upstream_gradient):\n",
    "        return upstream_gradient\n",
    "\n",
    "    return result, grad\n",
    "\n",
    "class QuantizedDense(layers.Layer):\n",
    "    \"\"\"A Dense layer that quantizes BOTH weights and activations to 4-bit discrete steps.\"\"\"\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                 initializer=\"glorot_uniform\", trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.units,), initializer=\"zeros\", trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Quantize Weights on the fly\n",
    "        w_q = dynamic_quant_ste(self.w)\n",
    "        # Quantize incoming Activations on the fly\n",
    "        x_q = dynamic_quant_ste(inputs)\n",
    "        # MatMul with quantized discrete tensors\n",
    "        return tf.matmul(x_q, w_q) + self.b\n",
    "\n",
    "# ==========================================\n",
    "# 3. Build the Transformer Networks\n",
    "# ==========================================\n",
    "def create_standard_transformer():\n",
    "    \"\"\"Baseline: Massive Continuous FP32 Memory footprint.\"\"\"\n",
    "    inputs = layers.Input(shape=(maxlen,))\n",
    "    x = layers.Embedding(vocab_size, 64)(inputs)\n",
    "    \n",
    "    attn = layers.MultiHeadAttention(num_heads=2, key_dim=64)(x, x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x + attn)\n",
    "    \n",
    "    # Standard Continuous FP32 Dense Blocks\n",
    "    ffn = layers.Dense(128, activation='relu')(x)\n",
    "    ffn = layers.Dense(64)(ffn)\n",
    "    \n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x + ffn)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "\n",
    "def create_quantized_transformer():\n",
    "    \"\"\"PoC: Lean Discrete INT4 Memory footprint.\"\"\"\n",
    "    inputs = layers.Input(shape=(maxlen,))\n",
    "    x = layers.Embedding(vocab_size, 64)(inputs)\n",
    "    \n",
    "    attn = layers.MultiHeadAttention(num_heads=2, key_dim=64)(x, x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x + attn)\n",
    "    \n",
    "    # Quantized W4A4 Dense Blocks\n",
    "    ffn = QuantizedDense(128)(x)\n",
    "    ffn = layers.ReLU()(ffn) # Standard ReLU acts on top of discrete steps\n",
    "    ffn = QuantizedDense(64)(ffn)\n",
    "    \n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x + ffn)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# ==========================================\n",
    "# 4. Compile and Train Side-by-Side\n",
    "# ==========================================\n",
    "model_std = create_standard_transformer()\n",
    "model_qnt = create_quantized_transformer()\n",
    "\n",
    "model_std.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_qnt.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "epochs = 10 # 10 epochs is usually enough for IMDB to converge\n",
    "\n",
    "print(\"--- Training Standard Transformer (Continuous FP32) ---\")\n",
    "history_std = model_std.fit(train_ds, validation_data=test_ds, epochs=epochs)\n",
    "\n",
    "print(\"\\n--- Training Quantized Transformer (Dynamic W4A4) ---\")\n",
    "history_qnt = model_qnt.fit(train_ds, validation_data=test_ds, epochs=epochs)\n",
    "\n",
    "# ==========================================\n",
    "# 5. Visualize Results\n",
    "# ==========================================\n",
    "print(\"\\nGenerating performance plots...\")\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, epochs + 1), history_std.history['val_accuracy'], label=\"Standard (FP32)\", linewidth=2, color='blue')\n",
    "plt.plot(range(1, epochs + 1), history_qnt.history['val_accuracy'], label=\"Quantized (W4A4)\", linewidth=2, color='red', linestyle='--')\n",
    "plt.title(\"IMDB Accuracy: Continuous vs. 4-bit Discrete (W4A4)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=':', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"imdb_tf_accuracy.png\", dpi=150)\n",
    "print(\"Saved plot -> imdb_tf_accuracy.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
